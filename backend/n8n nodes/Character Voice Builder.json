{
  "name": "Character Voice Builder",
  "nodes": [
    {
      "parameters": {
        "jsCode": "// TTS Job Builder → RunPod/Higgs API mapper\n// INPUT: items[0].json.tts = { segments, voices, wps, route, title, voice_ref_url, piggybank:{voice:{id,displayName}} }\n// OUTPUT: One item PER segment (mode: \"single\")\n\nconst root = items[0]?.json || {};\nconst tts = root.tts || {};\n\nconst segments = Array.isArray(tts.segments) ? tts.segments : [];\nconst voices = Array.isArray(tts.voices) ? tts.voices : [];\nconst globalRef = String(tts.voice_ref_url || '');\nconst piggyVoice = tts.piggybank?.voice || {};\n\n// ---- HELPER: Text Sanitization ----\nfunction sanitizeText(s) {\n    let t = (s == null ? '' : String(s));\n    t = t\n        .replace(/[\\u2018\\u2019\\u201B]/g, \"'\")\n        .replace(/[\\u201C\\u201D\\u201F]/g, '\"')\n        .replace(/\\u2026/g, '...');\n    t = t\n        .replace(/[\\u0000-\\u001F\\u2028\\u2029]/g, ' ')\n        .replace(/\\s+/g, ' ')\n        .trim();\n    return t;\n}\n\n// ---- HELPER: Voice Resolution ----\nconst voiceMap = new Map(\n    voices\n        .filter(v => v?.voiceId)\n        .map(v => [String(v.voiceId), { ...v, voiceId: String(v.voiceId) }])\n);\n\nfunction pickVoiceFor(seg) {\n    const segVid = seg.voiceId ? String(seg.voiceId) : '';\n    if (segVid && voiceMap.has(segVid)) return voiceMap.get(segVid);\n    if (piggyVoice?.id) {\n        return {\n            voiceId: String(piggyVoice.id),\n            name: String(piggyVoice.displayName || ''),\n        };\n    }\n    return { voiceId: segVid, name: '' };\n}\n\n// ---------------------------------------------------------\n// BUILD INDIVIDUAL JOBS\n// ---------------------------------------------------------\nconst jobs = segments.map(seg => {\n    const txt = sanitizeText(seg.text || '');\n    if (!txt) return null;\n\n    const v = pickVoiceFor(seg);\n\n    // 1. Identify potential sources\n    const vid = v.voiceId;\n    const localRef = String(seg.voice_ref_url || seg.speaker_reference_url || '');\n\n    // 2. Logic: Priority to Refs (Global > Local > Recording)\n    let finalRef = null;\n    let finalVid = null;\n\n    if (globalRef) {\n        finalRef = globalRef;\n    } else if (localRef) {\n        finalRef = localRef;\n    } else if (vid === \"recording\" && localRef) { // Explicit \"recording\" + url\n        finalRef = localRef;\n    } else if (vid && vid !== \"None\" && vid !== \"recording\") {\n        finalVid = vid;\n    }\n\n    // 3. Construct Turn\n    const turn = {\n        text: txt,\n        speaker: v.name || \"Narrator\",\n        pause_duration: 0.2\n    };\n\n    if (finalRef) {\n        turn.ref_audio_urls = [finalRef]; // Clone path\n    } else {\n        turn.voice_id = finalVid || \"en_us_001\"; // Standard path\n    }\n\n    // 4. Construct Payload (MULTI Mode - Single Turn)\n    // User Requirement: Keep mode \"multi\" but send one turn at a time\n    const payload = {\n        mode: \"multi\",\n        dialogue: [turn], // Array of 1\n        sample_rate: 24000,\n        max_new_tokens: 1200,\n        temperature: 0.3\n    };\n\n    // 5. Construct IDs\n    // beatId -> input or \"B01\"\n    // shotId -> input or \"S03\"\n    // segId  -> input segId or id\n    const segId = String(seg.segId || seg.id || '');\n    const beatId = String(seg.beatId || 'B01');\n    const shotId = String(seg.shotId || 'S01');\n\n    // shotKey -> input or SEG-BEAT-SHOT\n    let shotKey = String(seg.shotKey || '');\n    if (!shotKey && segId) {\n        shotKey = `${segId}-${beatId}-${shotId}`;\n    }\n\n    // 6. Return Item Wrapper\n    return {\n        json: {\n            input: payload, // Wrapped in input for standard API structure\n\n            // Metadata for downstream mapping (per job)\n            _expect: {\n                id: String(seg.id || seg.shotId || ''),\n                text: txt,\n                targetSec: seg.targetSec,\n                shotKey: shotKey,\n                segId: segId,\n                beatId: beatId,\n                shotId: shotId,\n                type: seg.type || null\n            }\n        }\n    };\n}).filter(Boolean); // Remove nulls (empty text)\n\nreturn jobs;\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        192,
        -176
      ],
      "id": "5901479e-0dfb-41be-8df3-35b0a8b7f821",
      "name": "Build TTS Jobs"
    },
    {
      "parameters": {
        "url": "=https://api.runpod.ai/v2/vms8w05ymko04a/status/{{ $json.jobId }}",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        960,
        0
      ],
      "id": "249ec4b2-e918-4c5a-aca6-972950d13b01",
      "name": "Get Character Voice",
      "credentials": {
        "httpHeaderAuth": {
          "id": "ZWfraTm614GIiwkI",
          "name": "Llama Script"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.runpod.ai/v2/vms8w05ymko04a/run",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "input",
              "value": "={{ $json.input }}"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        592,
        0
      ],
      "id": "9e0386aa-db72-4820-8cff-aac2484139a9",
      "name": "Request Character Voice",
      "credentials": {
        "httpHeaderAuth": {
          "id": "ZWfraTm614GIiwkI",
          "name": "Llama Script"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// -------------------------------------------------------\n// Parse TTS Results (Run Once for All Items)\n// -------------------------------------------------------\n\nfunction num(v, d = 0) {\n  const n = Number(v);\n  return Number.isFinite(n) ? n : d;\n}\nconst S = (v) => (v == null || v === '' ? null : String(v));\n\n// 1) grab all the raw JSON blobs\nconst rawItems = items.map(i => i.json || {});\n\n// helper: extract IDs from a TTS result row (prefer _expect)\n// Used for single items or as fallback\nfunction extractIds(r) {\n  const ex = r._expect || {};\n  const shotId  = S(r.shotId || r.shotID || ex.shotId);\n  const segId   = S(r.segId || ex.segId);\n  const beatId  = S(r.beatId || ex.beatId);\n  let shotKey   = S(r.shotKey || ex.shotKey);\n  if (!shotKey && segId && beatId && shotId) {\n    shotKey = `${segId}-${beatId}-${shotId}`;\n  }\n  return { shotKey, segId, beatId, shotId };\n}\n\n// prefer best available audio url\nfunction pickAudioUrl(r) {\n  return (\n    r.audio_url ||\n    r.url ||\n    r.output?.audio_url ||\n    r.output?.url ||\n    r.output?.upload?.url ||\n    null\n  );\n}\n\n// derive duration_sec with sensible fallbacks\nfunction pickDurationSec(r) {\n  // direct seconds\n  const direct =\n    num(r.duration_sec, NaN) ||\n    num(r.output?.duration_sec, NaN);\n\n  if (Number.isFinite(direct)) return direct;\n\n  // samples / rate\n  const samples = num(r.output?.duration_samples, NaN);\n  const rate    = num(r.output?.sampling_rate, NaN);\n  if (Number.isFinite(samples) && Number.isFinite(rate) && rate > 0) {\n    return samples / rate;\n  }\n\n  // ms → sec\n  const durMs = num(r.output?.duration_ms, NaN);\n  if (Number.isFinite(durMs)) return durMs / 1000;\n\n  // _expect end-start\n  const ex = r._expect || {};\n  const fallback = num(ex.endSec, NaN) - num(ex.startSec, NaN);\n  if (Number.isFinite(fallback) && fallback >= 0) return fallback;\n\n  return null;\n}\n\n// 2) normalize each into {id, segId, beatId, shotId, shotKey, type, audio_url, duration_sec, offset_sec}\n// We use flatMap to split \"multi\" results into individual segments if needed\nconst voices = rawItems.flatMap(r => {\n  const audioUrl    = pickAudioUrl(r);\n  const mainDuration = pickDurationSec(r);\n  const topType     = r.type ?? r._expect?.type ?? null;\n  \n  // PARSE MULTI-SEGMENT STRUCTURE\n  const expectSegs = Array.isArray(r._expect?.segments) ? r._expect.segments : [];\n  const outputSegs = Array.isArray(r.output?.segments) ? r.output.segments : [];\n  \n  // A) Multi-Segment Case: Explode into multiple items\n  if (expectSegs.length > 0) {\n     return expectSegs.map((es, idx) => {\n         // Try to find matching output segment timing, otherwise guess or use 0\n         const os = outputSegs[idx] || {};\n         \n         const start = num(os.start, 0);\n         const end   = num(os.end, 0);\n         let dur     = (end > start) ? (end - start) : num(es.targetSec, 0);\n         // Guard: if timing is missing but we only have 1 segment, use the file total duration\n         if (dur <= 0 && expectSegs.length === 1) dur = mainDuration || 0;\n         \n         // Extract IDs specifically from the segment object\n         const shotId = S(es.shotId || es.id); \n         const segId  = S(es.segId);\n         const beatId = S(es.beatId);\n         let shotKey  = S(es.shotKey);\n         if (!shotKey && segId && beatId && shotId) {\n             shotKey = `${segId}-${beatId}-${shotId}`;\n         }\n\n         return {\n             id: r.id || r.jobId || null, // Shared Job ID\n             shotKey,\n             segId,\n             beatId,\n             shotId,\n             type: es.type || topType, // <--- Prioritize segment type\n             audio_url: audioUrl,\n             duration_sec: dur,\n             offset_sec: start \n         };\n     });\n  }\n\n  // B) Single Item Case: Fallback to standard extraction\n  const ids = extractIds(r);\n  return [{\n    id:           r.id || r.jobId || null, \n    shotKey:      ids.shotKey,\n    segId:        ids.segId,\n    beatId:       ids.beatId,\n    shotId:       ids.shotId,\n    type:         topType,\n    audio_url:    audioUrl,\n    duration_sec: (mainDuration != null ? Number(mainDuration) : null),\n    offset_sec:   0 // Start at beginning\n  }];\n});\n\n// 3) build audio track clips\n// Note: We use 'in' = offset_sec to grab the correct slice of the audio\nconst clips = voices.map(v => ({\n  id:  v.segId || v.shotKey || v.shotId || undefined,\n  src: v.audio_url,\n  in:  v.offset_sec || 0,\n  out: (v.offset_sec || 0) + (v.duration_sec || 0),\n}));\n\n// 3.5) Lift common IDs to the top level if all voices agree (useful for a-roll)\nfunction commonOf(field) {\n  const vals = Array.from(new Set(voices.map(v => v[field]).filter(v => v != null)));\n  return vals.length === 1 ? vals[0] : null;\n}\nconst topShotKey = commonOf('shotKey');\nconst topSegId   = commonOf('segId');\nconst topBeatId  = commonOf('beatId');\nconst topShotId  = commonOf('shotId');\n\n// 4) emit one payload\nreturn [{\n  json: {\n    // essential IDs at top level (null if mixed across items)\n    shotKey: topShotKey,\n    segId:   topSegId,\n    beatId:  topBeatId,\n    shotId:  topShotId,\n\n    voices,\n    edl: {\n      tracks: {\n        audio: [\n          {\n            name: 'a_vo',\n            clips,\n          }\n        ]\n      }\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1280,
        -160
      ],
      "id": "6a4eb7b3-1a12-4c62-9954-7bc032f9bf9e",
      "name": "Parse TTS Result"
    },
    {
      "parameters": {
        "jsCode": "// -------------------------------------------------------\n// Aggregate Voices -> EDL  (Run Once for All Items)\n// -------------------------------------------------------\n\nconst root   = items[0]?.json || {};\nconst voices = root.voices ?? [];\n\n// Helper to find a common value across voices for a given field\nconst commonOf = (field) => {\n  const vals = Array.from(new Set(voices.map(v => v?.[field]).filter(v => v != null)));\n  return vals.length === 1 ? vals[0] : null;\n};\n\n// Prefer IDs already lifted to top-level by the previous node; else compute common from voices\nconst topShotKey = root.shotKey ?? commonOf('shotKey') ?? null;\nconst topSegId   = root.segId   ?? commonOf('segId')   ?? null;\nconst topBeatId  = root.beatId  ?? commonOf('beatId')  ?? null;\nconst topShotId  = root.shotId  ?? commonOf('shotId')  ?? null;\n\n// Build audio clips, preserving full ID set and type\nconst clips = voices.map(v => {\n  const segId   = v.segId   ?? topSegId   ?? v.shotId ?? undefined; // prefer segId; fallback to topSegId; then shotId\n  const beatId  = v.beatId  ?? topBeatId  ?? undefined;\n  const shotId  = v.shotId  ?? topShotId  ?? undefined;\n  const shotKey = v.shotKey ?? topShotKey ?? (segId && beatId && shotId ? `${segId}-${beatId}-${shotId}` : undefined);\n\n  return {\n    // Primary identifiers\n    id:      segId,        // maintain historical behavior (segId as clip id)\n    segId,\n    beatId,\n    shotId,\n    shotKey,\n\n    // Other fields\n    type:    v.type ?? null,                    // carry over type (aroll/broll)\n    src:     v.audio_url,\n    in:      0,\n    out:     Number(v.duration_sec) || 0,\n  };\n});\n\n// Optional: total program length (sum of clip durations)\nconst length_sec = Math.round(\n  clips.reduce((t, c) => t + ((c.out || 0) - (c.in || 0)), 0) * 1000\n) / 1000;\n\nreturn [{\n  json: {\n    // Keep original voices array\n    voices,\n\n    // Lift essential IDs to the top level for convenience (null if mixed)\n    shotKey: topShotKey,\n    segId:   topSegId,\n    beatId:  topBeatId,\n    shotId:  topShotId,\n\n    edl: {\n      tracks: {\n        audio: [\n          {\n            name: 'a_vo',\n            clips,\n          }\n        ]\n      }\n    },\n    length_sec,\n    // resolution / fps can be added here if you pass them in context\n    // resolution: { width: 1024, height: 1024 },\n    // fps: 30,\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1456,
        -160
      ],
      "id": "a50ccf0c-5c50-4ad8-91f0-e6630ab26c22",
      "name": "Aggregate Voices → EDL"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "33344dd9-529c-4682-89d7-a74d1ed44020",
              "leftValue": "={{ $json.status }}",
              "rightValue": "COMPLETED",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        1280,
        0
      ],
      "id": "cb4d3b32-4e80-4ed8-b211-221dfe5896b9",
      "name": "If"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        1456,
        16
      ],
      "id": "178d3062-4335-43ba-9207-05a598ecc4c0",
      "name": "Wait",
      "webhookId": "9978ef35-d5bf-4bf6-9e39-1717bf1b1a60"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [
        368,
        -112
      ],
      "id": "c6b33abf-be21-45f7-9a2d-360f83b72ac0",
      "name": "Loop Over Items"
    },
    {
      "parameters": {
        "jsCode": "// Run Once for All Items\n// We assume your sub-workflow is triggered with a single item:\n//   items[0].json.plan.ttsSegments\n\nconst { ttsSegments } = items[0].json.plan;\n\n// Turn each plan segment into the input shape for your Exec Character Voice Builder:\nconst jobs = ttsSegments.map(seg => ({\n  json: {\n    id:       seg.id,\n    text:     seg.text,\n    voiceId:  seg.voiceId\n  }\n}));\n\nreturn jobs;       // returns N items, one per segment"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        128,
        240
      ],
      "id": "2b712aee-f62c-46ca-958e-1e7c41364fe6",
      "name": "Mock Code"
    },
    {
      "parameters": {
        "inputSource": "passthrough"
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        16,
        -176
      ],
      "id": "0732c982-6430-4923-a4df-a68abccfb3f9",
      "name": "When Executed by Another Workflow"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "1c4b42c7-e96b-4d87-ae9f-445d22e52034",
              "name": "jobId",
              "value": "={{ $json.id }}",
              "type": "string"
            },
            {
              "id": "deb3b058-2a65-4ed9-ae62-10c9cd6828a7",
              "name": "shotID",
              "value": "={{$item(0).$node[\"Loop Over Items\"].json._expect.id}}",
              "type": "string"
            }
          ]
        },
        "includeOtherFields": true,
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        784,
        0
      ],
      "id": "cb77f4d4-00dc-4790-901d-b2daaa5f14ec",
      "name": "Edit Fields"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "63cbf27c-74d3-4c6d-aadb-33c7f1a37d6c",
              "name": "shotID",
              "value": "={{$item(0).$node[\"Loop Over Items\"].json._expect.id}}",
              "type": "string"
            },
            {
              "id": "9febf57a-5e85-482e-a121-b5d9d8c3d777",
              "name": "jobId",
              "value": "={{ $json.id }}",
              "type": "string"
            }
          ]
        },
        "includeOtherFields": true,
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1120,
        0
      ],
      "id": "0bd12e16-2ef6-4f7f-8389-39907fe5c0dc",
      "name": "Edit Fields1"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        -64,
        240
      ],
      "id": "d34f44b4-b2f2-4f6e-b3c7-3ca2c88ac01f",
      "name": "When clicking ‘Execute workflow’"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "options": {}
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        592,
        -160
      ],
      "id": "3482e0f2-731f-47fe-b8fa-ca8f46807560",
      "name": "Merge"
    }
  ],
  "pinData": {
    "When Executed by Another Workflow": [
      {
        "json": {
          "tts": {
            "segments": [
              {
                "segId": "SEG-01",
                "id": "SEG-01",
                "sceneId": "189023",
                "beatId": "B01",
                "type": "aroll",
                "text": "Hey everyone, I'm Demarco, and today we're diving into the future of AI tech.",
                "startSec": 0,
                "endSec": 11.25,
                "targetSec": 11.25,
                "track": "aroll",
                "videoType": "aroll",
                "driver": "character",
                "mode": "aroll",
                "requestId": "CO-7h8i9j",
                "orchestratorId": "CO-7h8i9j",
                "captions": {
                  "enabled": true,
                  "maxLen": 55,
                  "lines": [
                    "Hey everyone,",
                    "I'm Demarco,",
                    "and today we're diving into the future of AI tech."
                  ],
                  "lineCount": 3
                },
                "routeUsed": "combo",
                "voiceId": "recording",
                "seq": 1,
                "orderKey": "001-SEG-01"
              },
              {
                "segId": "SEG-03",
                "id": "SEG-03",
                "sceneId": "189023",
                "beatId": "B01",
                "type": "broll",
                "text": "Picture sleek AI hardware humming in the background, robots moving with precision, all while we explore how these innovations will shape our lives.",
                "startSec": 11.25,
                "endSec": 18.75,
                "targetSec": 7.5,
                "track": "broll",
                "videoType": "broll",
                "driver": "narrator",
                "mode": "broll_vo",
                "requestId": "CO-7h8i9j",
                "orchestratorId": "CO-7h8i9j",
                "captions": {
                  "enabled": false,
                  "maxLen": 55,
                  "lines": [],
                  "lineCount": 0
                },
                "routeUsed": "combo",
                "voiceId": "recording",
                "seq": 2,
                "orderKey": "002-SEG-03",
                "warn": "Text (23) may exceed 7.5s at 2.5 wps (≈18 max)."
              }
            ],
            "requests": [
              {
                "id": "SEG-01-B01",
                "segId": "SEG-01",
                "beatId": "B01",
                "sceneId": "189023",
                "voiceId": "recording",
                "wps": 2.5,
                "type": "aroll",
                "track": "aroll",
                "videoType": "aroll",
                "driver": "character",
                "mode": "aroll",
                "startSec": 0,
                "endSec": 11.25,
                "targetSec": 11.25,
                "text": "Hey everyone, I'm Demarco, and today we're diving into the future of AI tech.",
                "captions": {
                  "enabled": true,
                  "maxLen": 55,
                  "lines": [
                    "Hey everyone,",
                    "I'm Demarco,",
                    "and today we're diving into the future of AI tech."
                  ],
                  "lineCount": 3
                },
                "orderKey": "001-SEG-01",
                "children": [
                  {
                    "id": "SEG-01",
                    "orderKey": "001-SEG-01",
                    "startSec": 0,
                    "endSec": 11.25,
                    "targetSec": 11.25,
                    "type": "aroll"
                  }
                ]
              },
              {
                "id": "SEG-03-B01",
                "segId": "SEG-03",
                "beatId": "B01",
                "sceneId": "189023",
                "voiceId": "recording",
                "wps": 2.5,
                "type": "broll",
                "track": "broll",
                "videoType": "broll",
                "driver": "narrator",
                "mode": "broll_vo",
                "startSec": 11.25,
                "endSec": 18.75,
                "targetSec": 7.5,
                "text": "Picture sleek AI hardware humming in the background, robots moving with precision, all while we explore how these innovations will shape our lives.",
                "captions": {
                  "enabled": false,
                  "maxLen": 55,
                  "lines": [],
                  "lineCount": 0
                },
                "orderKey": "002-SEG-03",
                "children": [
                  {
                    "id": "SEG-03",
                    "orderKey": "002-SEG-03",
                    "startSec": 11.25,
                    "endSec": 18.75,
                    "targetSec": 7.5,
                    "type": "broll"
                  }
                ]
              }
            ],
            "voices": [
              {
                "voiceId": "recording",
                "name": "",
                "pitchSemitones": 0,
                "speed": 1,
                "emotion": "neutral",
                "energy": 0.5,
                "voiceAccent": "auto"
              }
            ],
            "wps": 2.5,
            "route": "combo",
            "title": "Demarco poetry",
            "voice_ref_url": "https://nyc3.digitaloceanspaces.com/media-catalog/staging/misc/recording_1766607381595.mp4",
            "piggybank": {
              "voice": {
                "id": "recording",
                "displayName": ""
              }
            }
          }
        }
      }
    ]
  },
  "connections": {
    "Build TTS Jobs": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          },
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Request Character Voice": {
      "main": [
        [
          {
            "node": "Edit Fields",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Character Voice": {
      "main": [
        [
          {
            "node": "Edit Fields1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse TTS Result": {
      "main": [
        [
          {
            "node": "Aggregate Voices → EDL",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Wait",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait": {
      "main": [
        [
          {
            "node": "Get Character Voice",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Aggregate Voices → EDL": {
      "main": [
        []
      ]
    },
    "Loop Over Items": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 1
          }
        ],
        [
          {
            "node": "Request Character Voice",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Mock Code": {
      "main": [
        []
      ]
    },
    "When Executed by Another Workflow": {
      "main": [
        [
          {
            "node": "Build TTS Jobs",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields": {
      "main": [
        [
          {
            "node": "Get Character Voice",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields1": {
      "main": [
        [
          {
            "node": "If",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "When clicking ‘Execute workflow’": {
      "main": [
        [
          {
            "node": "Mock Code",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge": {
      "main": [
        [
          {
            "node": "Parse TTS Result",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1",
    "callerPolicy": "workflowsFromSameOwner",
    "errorWorkflow": "OMsZG24WeF2YbuO6"
  },
  "versionId": "cf63879b-6d4c-4072-97f3-c3ab001b7139",
  "meta": {
    "instanceId": "46eff0d2c88fe6211d71052d4f59ef615c9804dfa61784c64b70e2dfd97395dd"
  },
  "id": "jKDc1cnUVzeC6Olg",
  "tags": [
    {
      "createdAt": "2025-08-06T22:47:34.330Z",
      "updatedAt": "2025-08-06T22:47:34.330Z",
      "id": "5W4ptl8eNWuki2da",
      "name": "Base_Level"
    },
    {
      "createdAt": "2025-08-06T22:46:44.898Z",
      "updatedAt": "2025-08-06T22:46:44.898Z",
      "id": "Fx3HZ4h0zLNrZrsf",
      "name": "Clip0"
    },
    {
      "createdAt": "2025-08-06T22:48:11.746Z",
      "updatedAt": "2025-08-06T22:48:11.746Z",
      "id": "K72jLWcSD75fEevX",
      "name": "Captions"
    },
    {
      "createdAt": "2025-08-06T22:52:24.148Z",
      "updatedAt": "2025-08-06T22:52:24.148Z",
      "id": "P9Kzi9BZmUKDAA9R",
      "name": "Character"
    },
    {
      "createdAt": "2025-08-06T22:47:27.709Z",
      "updatedAt": "2025-08-06T22:47:27.709Z",
      "id": "RDt1fEwBS590LEn1",
      "name": "Builder"
    },
    {
      "createdAt": "2025-08-06T22:50:20.731Z",
      "updatedAt": "2025-08-06T22:50:20.731Z",
      "id": "xwe3xqTwV9DYlfAh",
      "name": "Podcast"
    }
  ]
}