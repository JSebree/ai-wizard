{
  "name": "Music Builder",
  "nodes": [
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        -496,
        0
      ],
      "id": "00744908-fec3-4f7d-8f93-e209a3b05823",
      "name": "When clicking ‘Execute workflow’"
    },
    {
      "parameters": {
        "jsCode": "// pretend your planner handed down two music requests\nreturn [{\n  json: {\n    clips: [\n      {\n        id:               \"m0\",\n        length_target_sec: 60,\n        plan: {\n          global: {\n            music: {\n              tags: [\"uplifting\", \"cinematic\"]\n            }\n          }\n        }\n      },\n      {\n        id:               \"m1\",\n        length_target_sec: 30,\n        plan: {\n          global: {\n            music: {\n              tags: [\"ambient\", \"piano\"]\n            }\n          }\n        }\n      }\n    ]\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -320,
        0
      ],
      "id": "674f9fa6-9d1d-43ed-927b-e7f8c70baeb8",
      "name": "Mock Prompts"
    },
    {
      "parameters": {
        "jsCode": "// Music Payload Builder — RunPod/ACE-Step payloads (timeline or per-clip)\n//\n// Your RunPod handler expects:\n//   event.input = { tags: string, lyrics: string, duration: number, seed: number }\n//\n// We keep overlay/mix context (selectedInputUrl, volumes, etc.) in meta for downstream nodes.\n\nconst item = items[0].json || {};\nconst S    = item.settings || {};\nconst PB   = item.piggybank || {};\nconst PBM  = PB.music || {};                 // { tempoVal, vocals, ... }\nconst MH   = S.musicHints || {};             // { tempoVal, vocals, ducking }\nconst MV   = S.mixVolumes || {};             // { voice, music, fx, duckUnderVoice }\n\nconst mode = String(S.musicMode || 'timeline').toLowerCase(); // 'timeline' | 'per-clip'\nconst doMusic = Boolean(S.doMusic ?? item.doMusic ?? true);\n\n// NEW: normalize doHD flag from settings / top-level\nconst doHD = Boolean(S.doHD ?? item.doHD ?? false);\n\n// carry request identity through (root → settings → _meta)\nconst requestId = item.requestId ?? S.requestId ?? item._meta?.requestId ?? null;\n\n// -------- URL selection (for downstream overlay step; NOT sent to music API) --------\nconst fallbacks = {\n  musicInputUrl: S.musicInputUrl || null,\n  captionsInputUrl: S.captionsInputUrl || null,\n  edlFirstCaptionSrc: item.edl?.tracks?.captions?.[0]?.clips?.[0]?.src || null,\n  finalUrl: item.finalUrl || null\n};\nconst selectedInputUrl =\n  fallbacks.musicInputUrl ||\n  fallbacks.captionsInputUrl ||\n  fallbacks.edlFirstCaptionSrc ||\n  fallbacks.finalUrl ||\n  null;\n\n// -------- helpers --------\nconst toNumber = (x, d=0) => {\n  const n = Number(x);\n  return Number.isFinite(n) ? n : d;\n};\n\n// drive durations from captions if present; else video\nconst captionTrack = item.edl?.tracks?.captions?.[0];\nconst videoTrack   = item.edl?.tracks?.video?.[0];\nconst drivingClips = (captionTrack?.clips && captionTrack.clips.length)\n  ? captionTrack.clips\n  : ((videoTrack?.clips && videoTrack.clips.length) ? videoTrack.clips : []);\n\n// ---- robust total duration detection ----\n// Priority:\n// 0) explicit program_length from upstream compose\n// 1) settings.length_sec\n// 2) top-level item.durationSec\n// 3) edl.length_sec\n// 4) settings.durationSec (legacy)\n// 5) sum of driving clip durations\nconst progLen0   = toNumber(item.program_length ?? item.compose_request?.metadata?.program_length ?? item.metadata?.program_length, 0);\nconst sLenSec    = toNumber(S.length_sec, 0);\nconst itemDurSec = toNumber(item.durationSec, 0);\nconst edlLenSec  = toNumber(item.edl?.length_sec, 0);\nconst sDurLegacy = toNumber(S.durationSec, 0);\nconst clipSum    = drivingClips.reduce((s,c) => {\n  const cin  = toNumber(c.in, 0);\n  const cout = toNumber(c.out, 0);\n  return s + Math.max(0, cout - cin);\n}, 0);\n\n// choose first non-zero, rounded to ms\nlet totalDuration = progLen0 || sLenSec || itemDurSec || edlLenSec || sDurLegacy || clipSum || 0;\ntotalDuration = Math.max(0, toNumber(totalDuration, 0));\nif (totalDuration > 0) totalDuration = Math.round(totalDuration * 1000) / 1000;\n\n// -------- pull new music inputs (merged order: settings.music → item.music → legacy edl meta) --------\nconst musicSettings =\n  S.music\n  || item.music\n  || item.edl?._meta?.settings?.music\n  || {};\nconst categoryLabel = musicSettings.categoryLabel ?? null;\n\n// If UI didn’t supply label, we keep backward-compat prompt fallback.\nconst promptBase =\n  String(\n    S.music?.prompt ??\n    item.music?.prompt ??\n    S.musicPrompt ??\n    item.musicPrompt ??\n    ''\n  ).trim() || 'cinematic bed';\n\n// Optional: map dropdown labels → strong tag strings for ACE-Step\nconst TAGS_BY_LABEL = {\n  \"Rock Instrumental\": \"rock instrumental, electric guitar riffs, distorted guitar, bass guitar, drums, energetic, 140 bpm, live concert feel\",\n  \"Jazz Instrumental\": \"jazz instrumental, acoustic piano, upright bass, saxophone, brush drums, swing rhythm, smooth, 90 bpm, lounge vibe\",\n  \"Hip-Hop / Trap Beat\": \"hip hop instrumental, trap beat, 808 bass, hi hats, snare, kick drum, synth pads, 140 bpm, dark, atmospheric, street vibe\",\n  \"Orchestral / Cinematic\": \"orchestral instrumental, strings, violins, cellos, brass, woodwinds, timpani, cinematic, majestic, 70 bpm, dramatic\",\n  \"Lo-Fi / Chillhop\": \"lofi instrumental, chillhop, jazzy chords, dusty vinyl crackle, mellow piano, soft synths, laid-back drums, 80 bpm, relaxing, study vibe\",\n  \"EDM / House\": \"edm instrumental, deep house, synth bass, kick drum four on the floor, hi hats, synth plucks, 128 bpm, dance club, hypnotic\",\n  \"Ambient / Soundscape\": \"ambient instrumental, drones, evolving textures, synth pads, slow tempo, atmospheric, meditative, 60 bpm, ethereal\",\n  \"Reggae / Dub\": \"reggae instrumental, dub groove, offbeat guitar skank, bass groove, drums, echo effects, relaxed, 85 bpm, island vibe\",\n  \"Funk / Groove\": \"funk instrumental, slap bass, electric guitar, clavinet, brass stabs, groovy drums, upbeat, 110 bpm, danceable\",\n  \"Country / Folk\": \"country instrumental, acoustic guitar, banjo, fiddle, upright bass, light percussion, warm, 95 bpm, rustic, storytelling vibe\",\n  \"Blues\": \"blues instrumental, electric guitar, walking bass, harmonica, shuffle drums, soulful, 85 bpm, smoky bar vibe\",\n  \"Metal\": \"metal instrumental, distorted guitars, double kick drums, bass, aggressive riffs, fast tempo, 180 bpm, heavy and dark\",\n  \"Techno\": \"techno instrumental, pounding kick, arpeggiated synths, dark bassline, industrial, 125 bpm, underground rave vibe\",\n  \"Latin / Salsa\": \"latin instrumental, salsa rhythm, congas, bongos, brass, piano montuno, bass, upbeat, 95 bpm, lively\",\n  \"R&B / Soul\": \"r&b instrumental, electric piano, smooth bass, soulful guitar, mellow drums, romantic, 85 bpm, groovy\",\n  \"Gospel\": \"gospel instrumental, organ, piano, choir pads, clapping rhythm, uplifting, 80 bpm, soulful, church vibe\",\n  \"Indian Classical / Sitar\": \"indian instrumental, sitar, tabla, tanpura drone, meditative, 70 bpm, spiritual, raga inspired\",\n  \"African Percussion\": \"african instrumental, djembe, talking drum, congas, rhythmic ensemble, tribal, 100 bpm, primal, energetic\",\n  \"Celtic / Folk\": \"celtic instrumental, flute, bagpipes, fiddle, harp, bodhran, traditional, 95 bpm, mystical\",\n  \"Synthwave / Retro\": \"synthwave instrumental, retro synths, arpeggios, electronic drums, nostalgic, 100 bpm, 1980s vibe\"\n};\n\n// Build tags from label (preferred) + append tempo/vocals hints; else fallback to prompt\nconst tempoVal   = toNumber(MH.tempoVal ?? PBM.tempoVal, 0) || null;\nconst vocalsFlag = (MH.vocals ?? PBM.vocals);\n\nconst baseFromLabel = categoryLabel && TAGS_BY_LABEL[categoryLabel] ? TAGS_BY_LABEL[categoryLabel] : null;\n\nconst tagsParts  = [\n  baseFromLabel || promptBase,\n  (tempoVal ? `tempo=${tempoVal}bpm` : null),\n  (vocalsFlag === false) ? 'no vocals' : null\n].filter(Boolean);\nconst tags = tagsParts.join(', ');\n\n// -------- seed handling (prefer explicit seed from merged musicSettings) --------\nconst seedLocked = PB?.render?.seedLock === true;\nconst edlSeedRaw = musicSettings.seed;\nconst edlSeed    = Number.isFinite(+edlSeedRaw) ? Math.trunc(+edlSeedRaw) : null;\n\n// If UI/EDL gave a seed, use it; else fall back to prior behavior\nconst baseSeed   = edlSeed ?? 31337;\nconst seedRandom = baseSeed + Math.floor(Math.random() * 1000);\nconst seed       = edlSeed !== null ? edlSeed : (seedLocked ? baseSeed : seedRandom);\n\n// -------- lyrics (optional; still off by default for instrumentals) --------\nconst lyrics = \"\"; // keep as-is; wire later if you decide to pass ui.lyrics\n\n// common meta for downstream mixer/overlay\nconst baseMeta = {\n  source: item.source || 'music-payload-v1',\n  routeUsed: item.routeUsed || S.routeUsed || null,\n  fps: S.fps || item.fps || item.edl?.fps || 30,\n  resolution: S.resolution || item.resolution || item.edl?.resolution || { width: 1920, height: 1080 },\n  requestId,\n  selectedInputUrl,\n  doHD,                    // <-- pass doHD in meta\n  fallbacksTried: fallbacks,\n  // carry mix & piggybank levers for the overlay stage\n  mixVolumes: {\n    voice: 1,                         // force voice level = 1\n    music: 0.1,                       // force music level = 0.1\n    fx: toNumber(MV.fx, 0.5),\n    duckUnderVoice: toNumber(MV.duckUnderVoice, 0.8),\n  },\n  musicHints: {\n    tempoVal,\n    vocals: (vocalsFlag === undefined ? null : Boolean(vocalsFlag)),\n    ducking: MH.ducking ?? null,\n  },\n  piggybank: PB || {}\n};\n\n// If doMusic is false, emit a no-op record so the workflow can short-circuit gracefully.\nif (!doMusic) {\n  return [{\n    json: {\n      skip: true,\n      reason: 'doMusic=false',\n      doHD,                 // <-- also expose at top level\n      meta: { ...baseMeta, mode, duration: totalDuration, tags, seed }\n    }\n  }];\n}\n\n// -------- MODE A: timeline (single bed) --------\nif (mode === 'timeline') {\n  return [{\n    json: {\n      doHD,                 // <-- top-level flag for downstream\n      input: {\n        // Only fields the RunPod handler actually reads:\n        tags,               // string\n        lyrics,             // string\n        duration: totalDuration, // = program length\n        seed\n      },\n      meta: {\n        ...baseMeta,\n        clipIds: drivingClips.map(c => c.id),\n        mode: 'timeline',\n        // expose what we used for transparency\n        musicCategoryLabel: categoryLabel || null\n      }\n    }\n  }];\n}\n\n// -------- MODE B: per-clip (one payload per clip) --------\nif (!drivingClips.length) {\n  // fall back to timeline if no clips\n  return [{\n    json: {\n      doHD,\n      input: { tags, lyrics, duration: totalDuration, seed },\n      meta: { ...baseMeta, clipIds: [], mode: 'timeline-fallback', musicCategoryLabel: categoryLabel || null }\n    }\n  }];\n}\n\nreturn drivingClips.map((c, idx) => {\n  const cin  = toNumber(c.in, 0);\n  const cout = toNumber(c.out, 0);\n  const dur  = Math.max(0.5, Math.max(0, cout - cin)); // floor tiny requests\n\n  return {\n    json: {\n      doHD,\n      input: {\n        tags,\n        lyrics,\n        duration: dur,                                   // per-clip exact window\n        seed: (edlSeed !== null) ? edlSeed : (seedLocked ? seed : (seed + idx)) // vary if not locked and no explicit seed\n      },\n      meta: {\n        ...baseMeta,\n        clipIds: [c.id],\n        mode: 'per-clip',\n        clipIndex: idx,\n        clipWindow: { in: cin, out: cout },\n        musicCategoryLabel: categoryLabel || null\n      }\n    }\n  };\n});"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -304,
        -480
      ],
      "id": "f50b0bb4-4c02-48f8-aef0-a30a69c9b93f",
      "name": "Payload Builder"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        976,
        -304
      ],
      "id": "f38d97a4-b7fa-43ca-8d81-d05c62571f73",
      "name": "Wait for scores",
      "webhookId": "0810024f-dd22-4e58-87e4-1052494fe853"
    },
    {
      "parameters": {
        "jsCode": "// Parse Music Result — normalize RunPod music response for downstream mix\n// Mode: Run once for ALL items\n\nreturn items.map(item => {\n  const j    = item.json || {};\n  const inp  = j.input || {};\n  const meta = j.meta  || {};\n  const out  = j.output || {};\n\n  // ---- core asset ----\n  const musicUrl = out?.audio?.url ?? null;\n\n  // Duration: API doesn’t return it, so fall back to what we requested\n  const durationSec =\n    (typeof out?.audio?.duration_sec === 'number' ? out.audio.duration_sec : null) ??\n    (typeof inp?.duration === 'number' ? inp.duration : null);\n\n  // Clip ids (array-safe)\n  const clipIds = Array.isArray(meta.clipIds)\n    ? meta.clipIds\n    : (meta.clipId ? [meta.clipId] : []);\n\n  // Tags / prompt fields (normalize to `tags`, keep `prompt` alias if any tool expects it)\n  const tags   = out?.tags ?? inp?.tags ?? null;\n  const prompt = tags; // alias\n\n  // Route, fps, resolution, and “which video” we mixed to\n  const routeUsed   = meta.routeUsed ?? null;\n  const fps         = (typeof meta.fps === 'number' ? meta.fps : null);\n  const resolution  = meta.resolution ?? null;\n  const inputUrl    = meta.selectedInputUrl || inp.input_url || null;\n\n  // Volumes & music hint levers (carry through for final mix)\n  const mixVolumes = meta.mixVolumes || null;   // { voice, music, fx, duckUnderVoice }\n  const musicHints = meta.musicHints || null;   // { tempoVal, vocals, ducking }\n  const piggybank  = meta.piggybank  || null;   // piggybank dials if present\n\n  // Seed: prefer output seed, else the one we asked for\n  const seed = (typeof out?.seed === 'number')\n    ? out.seed\n    : (typeof inp?.seed === 'number' ? inp.seed : null);\n\n  // Status/diagnostics\n  const status        = j.status || null;\n  const workerId      = j.workerId || null;\n  const jobId         = j.id || null; // debug-only local id (renamed from requestId → jobId)\n  const delayTime     = (typeof j.delayTime === 'number' ? j.delayTime : null);\n  const executionTime = (typeof j.executionTime === 'number' ? j.executionTime : null);\n\n  // Threaded workflow requestId (critical)\n  const requestId = meta.requestId ?? j.requestId ?? null;\n\n  // Mode: 'timeline' | 'per-clip' (default to timeline)\n  const mode = String(meta.mode || 'timeline');\n\n  // NEW: normalize doHD from meta/top-level\n  const doHD = Boolean(meta.doHD ?? j.doHD ?? false);\n\n  return {\n    json: {\n      // identity / grouping\n      clipIds,\n      mode,\n\n      // music asset\n      music_url: musicUrl,\n      duration_sec: durationSec,\n\n      // normalized creative context\n      tags,\n      prompt,     // alias of tags\n      seed,\n      musicPack: meta.musicPack ?? null,\n\n      // render/mix context\n      routeUsed,\n      fps,\n      resolution,\n      input_url: inputUrl,\n      doHD,              // <-- pass through doHD for final mix\n\n      // audio mix levers for the final overlay step\n      mixVolumes,      // { voice, music, fx, duckUnderVoice }\n      musicHints,      // { tempoVal, vocals, ducking }\n      piggybank,       // pass full piggybank if you included it upstream\n\n      // threaded workflow identifier (critical)\n      requestId,\n\n      // status/diagnostics\n      status,\n      workerId,\n\n      _meta: {\n        source: meta.source || null,\n        fallbacksTried: meta.fallbacksTried || null,\n        jobId,         // debug-only\n        delayTime,\n        executionTime,\n        doHD          // <-- also mirrored into _meta for debugging\n      }\n    }\n  };\n});"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        256,
        -464
      ],
      "id": "70563b53-ff25-4204-93a4-5805ac7fb1da",
      "name": "Parse Music Result"
    },
    {
      "parameters": {
        "jsCode": "// Build Music EDL — updated for new shape + compose hint for audio layering\n// Run Once For All Items\n\nconst rows = $items().map(i => i.json);\nif (!rows.length) throw new Error('Build Music EDL: no rows');\n\n// --- helpers ---\nconst toNum = (v, d=0) => {\n  const n = Number(v);\n  return Number.isFinite(n) ? n : d;\n};\n\n// 1) Collect music clips (ignore empties)\nconst clips = rows\n  .map(r => ({\n    src: r.music_url || null,\n    in:  0,\n    out: toNum(r.duration_sec, 0),\n  }))\n  .filter(c => !!c.src);\n\n// Guard\nif (!clips.length) throw new Error('Build Music EDL: no music_url found to mix');\n\n// 2) Duration strategy: timeline sums (your default)\nconst mode = String(rows[0]?.mode || 'timeline').toLowerCase();\nconst totalLength = mode === 'timeline'\n  ? clips.reduce((s, c) => s + toNum(c.out, 0), 0)\n  : Math.max(...clips.map(c => toNum(c.out, 0)), 0, 0);\n\n// 3) Pull shared fields + user settings from the first row\nconst first = rows[0] || {};\nconst requestId = first.requestId ?? first._meta?.requestId ?? null;\nconst resolution = first.resolution || { width: 1920, height: 1080 };\nconst fps        = toNum(first.fps, 30);\n\n// NEW: normalize doHD from parsed music result → carry forward\nconst doHD = Boolean(first.doHD ?? first._meta?.doHD ?? false);\n\n// Select the target/base video that music aligns to (same priority order)\nconst inputUrl =\n  first.input_url ||\n  first._meta?.fallbacksTried?.musicInputUrl ||\n  first._meta?.fallbacksTried?.captionsInputUrl ||\n  first._meta?.fallbacksTried?.edlFirstCaptionSrc ||\n  null;\n\nif (!inputUrl) throw new Error('Build Music EDL: missing target video url (input_url/fallbacks)');\n\n// Mix levers (user → defaults)\nconst mv = first.mixVolumes || {};\nconst voiceGain = toNum(mv.voice, 1);           // gain for voice (video track)\nconst musicGain = toNum(mv.music, 0.15);        // DEFAULT LOWER: music bed at 0.15\nconst fxGain    = toNum(mv.fx, 0.5);            // not used here, but passed along\nconst duckUnderVoice = toNum(mv.duckUnderVoice, 0.8); // hint; not applied in static amix\n\n// Hints + piggybank passthrough\nconst musicHints = first.musicHints || {};\nconst piggybank  = first.piggybank  || {};\nconst routeUsed  = first.routeUsed  || null;\n\n// 4) Settings payload for downstream (final mix)\nconst settings = {\n  doMusic: true,\n  doHD,                              // <-- pass doHD into settings\n  routeUsed,\n  fps,\n  resolution,\n  durationSec: totalLength,\n  inputUrl,                         // base video to mix onto\n  clipIds: Array.isArray(first.clipIds) ? first.clipIds : [],\n  musicPack: first.musicPack ?? null,\n  musicPrompt: first.prompt ?? first.tags ?? null,\n  musicHints,\n  mixVolumes: {\n    voice: voiceGain,\n    music: musicGain,\n    fx: fxGain,\n    duckUnderVoice\n  },\n  piggybank,\n  requestId\n};\n\n// 5) Build the EDL object (reference form)\nconst edl = {\n  tracks: {\n    audio: [\n      {\n        name: 'music',\n        clips, // [{ src, in, out }]\n      },\n    ],\n  },\n  resolution,\n  fps,\n  length_sec: totalLength,\n  _meta: {\n    target_url: inputUrl,\n    musicPrompt: settings.musicPrompt,\n    seed: first.seed ?? null,\n    tags: first.tags ?? null,\n    source: first._meta?.source ?? null,\n    requestId\n  },\n};\n\n// 6) Compose hint (matches your audio-layering endpoint)\n// Inputs: [0] base video (voice baked in), [1] generated music\n// Filters: scale volumes then amix → [outa]\n// Output: copy video stream, encode aac for audio\nconst musicFile = clips[0]?.src; // timeline mode → one bed; per-clip could be extended\nif (!musicFile) throw new Error('Build Music EDL: no music file to mix');\n\nconst compose_hint = {\n  inputs: [\n    { file_url: inputUrl },\n    { file_url: musicFile }\n  ],\n  filters: [\n    {\n      // simple linear gain mix; ducking is a future enhancement if you want sidechain/compand\n      filter: `[0:a]volume=${voiceGain}[v0];` +\n              `[1:a]volume=${musicGain}[m0];` +\n              `[v0][m0]amix=inputs=2:duration=longest[outa]`\n    }\n  ],\n  outputs: [\n    {\n      options: [\n        { option: '-map',   argument: '0:v' },\n        { option: '-map',   argument: '[outa]' },\n        { option: '-c:v',   argument: 'copy' },\n        { option: '-c:a',   argument: 'aac'   },\n        { option: '-b:a',   argument: '192k'  },\n        { option: '-movflags', argument: '+faststart' },\n        { option: '-shortest', argument: '' }\n      ]\n    }\n  ],\n  id: 'audio-layering'\n};\n\n// 7) Emit single item with EDL + settings + compose hint\nreturn [{\n  json: {\n    source: 'music-edl-v1',\n    edl,\n    settings,\n    compose_hint,\n    doHD                // <-- also available at the top level\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        432,
        -464
      ],
      "id": "23ea2722-d701-44bd-ab01-b1625d3c9b7c",
      "name": "Build Music EDL"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.runpod.ai/v2/gllgz1ipfunewi/run",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        64,
        -320
      ],
      "id": "f5c9adaa-4800-4187-97fb-54abef050de7",
      "name": "Generate Music",
      "credentials": {
        "httpHeaderAuth": {
          "id": "ZWfraTm614GIiwkI",
          "name": "Llama Script"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "26c0dcb4-1f40-4e91-ac77-3bb978dd4db2",
              "name": "id",
              "value": "={{ $json.id }}",
              "type": "string"
            },
            {
              "id": "88126913-3bbd-4ea7-bd45-f9b3671fa4c4",
              "name": "status",
              "value": "={{ $json.status }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        256,
        -320
      ],
      "id": "dbe24f8a-d681-406e-8be9-39ca032d9384",
      "name": "Set Music ID"
    },
    {
      "parameters": {
        "url": "=https://api.runpod.ai/v2/gllgz1ipfunewi/status/{{ $json.id }}",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        432,
        -320
      ],
      "id": "5a324bcd-96d0-4997-b708-b117936bf367",
      "name": "Get Music Status",
      "credentials": {
        "httpHeaderAuth": {
          "id": "ZWfraTm614GIiwkI",
          "name": "Llama Script"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "3678924d-e04e-4774-9f36-d79eaf7c0492",
              "leftValue": "={{ $json.status }}",
              "rightValue": "COMPLETED",
              "operator": {
                "type": "string",
                "operation": "equals",
                "name": "filter.operator.equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        784,
        -320
      ],
      "id": "62d6fe33-aa57-4702-9384-02bc26264897",
      "name": "Music complete?"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [
        -128,
        -432
      ],
      "id": "ee4ae455-1836-485d-bca8-2e08366b3d52",
      "name": "Loop Over Items"
    },
    {
      "parameters": {
        "inputSource": "passthrough"
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        -480,
        -480
      ],
      "id": "adfe32a2-0778-4007-93f3-017566f65cfd",
      "name": "When Executed by Another Workflow"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "options": {}
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        64,
        -464
      ],
      "id": "5b46f95c-2b9d-4c97-b8f5-16c0ced5cd8a",
      "name": "Merge"
    },
    {
      "parameters": {
        "mode": "raw",
        "jsonOutput": "={{ $json }}\n",
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        608,
        -320
      ],
      "id": "b29c09e6-dbc6-4dec-b346-1b04587ea7ad",
      "name": "Edit Fields"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://n8n-nca-toolkit-9mavn.ondigitalocean.app/v1/ffmpeg/compose",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"inputs\": [\n    { \"file_url\": \"{{ $json.edl._meta.target_url }}\" },\n    { \"file_url\": \"{{ $json.edl.tracks.audio[0].clips[0].src }}\" }\n  ],\n  \"filters\": [\n    {\n      \"filter\": \"[0:a]volume={{ $json.settings.mixVolumes.voice ?? 1 }}[audio1];[1:a]volume={{ $json.settings.mixVolumes.music ?? 0.15 }}[audio2];[audio1][audio2]amix=inputs=2:duration=longest[outa]\"\n    }\n  ],\n  \"outputs\": [\n    {\n      \"options\": [\n        { \"option\": \"-map\",      \"argument\": \"0:v\" },\n        { \"option\": \"-map\",      \"argument\": \"[outa]\" },\n        { \"option\": \"-c:v\",      \"argument\": \"copy\" },\n        { \"option\": \"-c:a\",      \"argument\": \"aac\" },\n        { \"option\": \"-b:a\",      \"argument\": \"192k\" },\n        { \"option\": \"-movflags\", \"argument\": \"+faststart\" }\n      ]\n    }\n  ],\n  \"id\": \"audio-layering\",\n  \"webhook_url\": \"https://n8n.simplifies.click/webhook/FinalMusicUrl\"\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        624,
        -576
      ],
      "id": "0d61141d-ad8f-4c30-bb7d-6846fa2af930",
      "name": "Mix music and video",
      "credentials": {
        "httpHeaderAuth": {
          "id": "kYUz8gwWtyRXykmg",
          "name": "Header Auth account"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "b979a9ec-ba5c-43cd-ae66-0d162004927d",
              "name": "response[0].file_url",
              "value": "={{ $json.musicUrl }}",
              "type": "string"
            },
            {
              "id": "4ff81714-a45f-4e0a-be9a-fe8488af57b3",
              "name": "doMusic",
              "value": "={{ $('When Executed by Another Workflow').item.json.settings.doMusic }}",
              "type": "boolean"
            },
            {
              "id": "dfbbc98b-ff38-4da4-a56e-371b255c0c8b",
              "name": "doCaptions",
              "value": "={{ $('When Executed by Another Workflow').item.json.settings.doCaptions }}",
              "type": "boolean"
            },
            {
              "id": "74ad9f0d-7d02-4745-a8b3-442309db3328",
              "name": "doHD",
              "value": "={{ $('When Executed by Another Workflow').item.json.settings.doHD }}",
              "type": "boolean"
            },
            {
              "id": "ed12b82b-ed4a-4c4b-bdb0-75caaaa09f06",
              "name": "captions_url",
              "value": "={{ $('When Executed by Another Workflow').item.json.settings.captionsInputUrl }}",
              "type": "string"
            },
            {
              "id": "696215bc-7dd3-41da-b9e3-bd984ede7667",
              "name": "music_url",
              "value": "={{ $json.musicUrl }}",
              "type": "string"
            },
            {
              "id": "33e8bf79-0538-4333-b246-012d52e1aec6",
              "name": "requestId",
              "value": "={{ $json.settings.requestId }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1712,
        -480
      ],
      "id": "639fb9ec-a32f-4ae9-a765-1384058ab205",
      "name": "Final Video Output"
    },
    {
      "parameters": {
        "mode": "combine",
        "combineBy": "combineByPosition",
        "options": {}
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        1536,
        -480
      ],
      "id": "b0d9b4eb-7e5e-4a84-8864-e4a2befff0d4",
      "name": "Merge1"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [
        1280,
        -416
      ],
      "id": "60ccbc23-50f7-4a69-97d7-7e8e78c2b2a5",
      "name": "Wait for caption",
      "webhookId": "0810024f-dd22-4e58-87e4-1052494fe853"
    },
    {
      "parameters": {
        "resource": "bucket",
        "operation": "search",
        "bucketName": "n8n-nca-bucket",
        "additionalFields": {
          "prefix": "=n8n-nca-bucket/{{ $json.job_id }}_output_0.mp4"
        }
      },
      "type": "n8n-nodes-base.s3",
      "typeVersion": 1,
      "position": [
        800,
        -576
      ],
      "id": "a822ab7c-d5d1-49ce-9c46-40e487bc3d98",
      "name": "Search music in bucket",
      "alwaysOutputData": false,
      "credentials": {
        "s3": {
          "id": "UwjAKScLP91wEOiS",
          "name": "S3 account"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 2
          },
          "conditions": [
            {
              "id": "d4c9089a-f5ac-47cc-b800-abd96c2c2e33",
              "leftValue": "={{ $('Search music in bucket').item.json.Key }}",
              "rightValue": "=n8n-nca-bucket/{{ $json.job_id }}_output_0.mp4",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        1152,
        -576
      ],
      "id": "404dcf6f-c9c3-482c-9a77-7472fa95499e",
      "name": "Music complete?1"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "7cf6d0c2-f237-4e9d-94d4-296fb9e05cc2",
              "name": "musicUrl",
              "value": "=https://n8n-nca-bucket.nyc3.digitaloceanspaces.com/{{ $('Search music in bucket').item.json.Key }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1344,
        -592
      ],
      "id": "79a9a3ec-08f8-474f-9078-f15f487540c8",
      "name": "Music Video URL"
    },
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "FinalMusicUrl",
        "options": {}
      },
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -480,
        -720
      ],
      "id": "3cfa47e3-3c76-452a-92ac-5929abfdae7f",
      "name": "Webhook",
      "webhookId": "6845965e-d2b2-4df6-90ca-ffa748d109c0"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "547da7e2-04e3-4337-9947-82d87f15b44b",
              "name": "job_id",
              "value": "={{ $('Mix music and video').item.json.job_id }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        976,
        -576
      ],
      "id": "590a4889-c621-47df-82fb-1df78d4d933d",
      "name": "Set Music Video ID"
    }
  ],
  "pinData": {
    "When Executed by Another Workflow": [
      {
        "json": {
          "source": "captions-edl-v1",
          "requestId": null,
          "doHD": true,
          "edl": {
            "tracks": {
              "captions": [
                {
                  "name": "cc",
                  "clips": [
                    {
                      "id": "clip-0",
                      "src": "https://n8n-nca-bucket.nyc3.digitaloceanspaces.com/n8n-nca-bucket/ad90e1fe-beeb-414d-84f6-7c1b4e51ba27_captioned.mp4",
                      "in": 0,
                      "out": 31.233
                    }
                  ]
                }
              ]
            },
            "resolution": {
              "width": 1024,
              "height": 576
            },
            "fps": 30,
            "length_sec": 31.233
          },
          "music": {
            "enabled": true,
            "prompt": null,
            "categoryLabel": "Orchestral / Cinematic",
            "seed": 390869799,
            "genre": null,
            "mood": null,
            "bpm": null,
            "volume": 0.1,
            "vocals": false
          },
          "settings": {
            "doCaptions": true,
            "doMusic": true,
            "doHD": true,
            "requestId": null,
            "musicPack": null,
            "musicPrompt": null,
            "musicHints": {
              "tempoVal": null,
              "vocals": false,
              "ducking": null
            },
            "mixVolumes": {
              "voice": 0,
              "music": 0.1,
              "fx": 0.5,
              "duckUnderVoice": 0.8
            },
            "fps": 30,
            "resolution": {
              "width": 1024,
              "height": 576
            },
            "durationSec": 31.233,
            "captionsInputUrl": "https://n8n-nca-bucket.nyc3.digitaloceanspaces.com/n8n-nca-bucket/ad90e1fe-beeb-414d-84f6-7c1b4e51ba27_captioned.mp4",
            "musicInputUrl": "https://n8n-nca-bucket.nyc3.digitaloceanspaces.com/n8n-nca-bucket/ad90e1fe-beeb-414d-84f6-7c1b4e51ba27_captioned.mp4",
            "music": {
              "enabled": true,
              "prompt": null,
              "categoryLabel": "Orchestral / Cinematic",
              "seed": 390869799,
              "genre": null,
              "mood": null,
              "bpm": null,
              "volume": 0.1,
              "vocals": false
            }
          }
        }
      }
    ]
  },
  "connections": {
    "When clicking ‘Execute workflow’": {
      "main": [
        [
          {
            "node": "Mock Prompts",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Mock Prompts": {
      "main": [
        []
      ]
    },
    "Payload Builder": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          },
          {
            "node": "Merge",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait for scores": {
      "main": [
        [
          {
            "node": "Get Music Status",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Music Result": {
      "main": [
        [
          {
            "node": "Build Music EDL",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Music EDL": {
      "main": [
        [
          {
            "node": "Mix music and video",
            "type": "main",
            "index": 0
          },
          {
            "node": "Merge1",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Generate Music": {
      "main": [
        [
          {
            "node": "Set Music ID",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Set Music ID": {
      "main": [
        [
          {
            "node": "Get Music Status",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Music Status": {
      "main": [
        [
          {
            "node": "Edit Fields",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Music complete?": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Wait for scores",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Loop Over Items": {
      "main": [
        [
          {
            "node": "Merge",
            "type": "main",
            "index": 1
          }
        ],
        [
          {
            "node": "Generate Music",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "When Executed by Another Workflow": {
      "main": [
        [
          {
            "node": "Payload Builder",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge": {
      "main": [
        [
          {
            "node": "Parse Music Result",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Edit Fields": {
      "main": [
        [
          {
            "node": "Music complete?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Mix music and video": {
      "main": [
        [
          {
            "node": "Search music in bucket",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge1": {
      "main": [
        [
          {
            "node": "Final Video Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait for caption": {
      "main": [
        [
          {
            "node": "Search music in bucket",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Search music in bucket": {
      "main": [
        [
          {
            "node": "Set Music Video ID",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Music complete?1": {
      "main": [
        [
          {
            "node": "Music Video URL",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Wait for caption",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Music Video URL": {
      "main": [
        [
          {
            "node": "Merge1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Set Music Video ID": {
      "main": [
        [
          {
            "node": "Music complete?1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1",
    "callerPolicy": "workflowsFromSameOwner",
    "errorWorkflow": "OMsZG24WeF2YbuO6"
  },
  "versionId": "7ad57f35-28fd-4bd6-bbf0-155492f5b25e",
  "meta": {
    "instanceId": "46eff0d2c88fe6211d71052d4f59ef615c9804dfa61784c64b70e2dfd97395dd"
  },
  "id": "GGOn96cLHKKZnveZ",
  "tags": [
    {
      "createdAt": "2025-08-06T22:47:34.330Z",
      "updatedAt": "2025-08-06T22:47:34.330Z",
      "id": "5W4ptl8eNWuki2da",
      "name": "Base_Level"
    },
    {
      "createdAt": "2025-08-06T22:46:44.898Z",
      "updatedAt": "2025-08-06T22:46:44.898Z",
      "id": "Fx3HZ4h0zLNrZrsf",
      "name": "Clip0"
    },
    {
      "createdAt": "2025-08-06T22:47:27.709Z",
      "updatedAt": "2025-08-06T22:47:27.709Z",
      "id": "RDt1fEwBS590LEn1",
      "name": "Builder"
    },
    {
      "createdAt": "2025-08-06T22:47:48.571Z",
      "updatedAt": "2025-08-06T22:47:48.571Z",
      "id": "rSILtO5ZKdvpHV5p",
      "name": "Music"
    }
  ]
}